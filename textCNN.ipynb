{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serereuk/Information_retrieval/blob/master/textCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLH5fYvhZWWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca27d5ff-3e5c-46da-9a4d-53140af830f3"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQAlvzlYnJH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MO3AHmqnKVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd '/content/drive/My Drive/information/CNN, RNN/CNN/rt-polaritydata(MR)/rt-polaritydata'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ4UyxP-o3sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, Dense, Dropout, GlobalMaxPooling1D, ReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOj4GYRIp6I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Reader(text_file_path):\n",
        "    data = [];\n",
        "    for i in text_file_path:\n",
        "        data += open(i, 'r', encoding=\"ISO-8859-1\").readlines()\n",
        "    label = [0] * int(len(data)/2) + [1] * int(len(data)/2)\n",
        "    for i in range(len(data)):\n",
        "        data[i] = re.sub('^\\W+', \"\", data[i].lower().strip())\n",
        "    return data, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnuWWKDBxDOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Indexing_padding(data, tok=None):\n",
        "    if tok == None:\n",
        "        tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "        tokenizer.fit_on_texts(data)\n",
        "    else:\n",
        "        tokenizer = tok\n",
        "    tensor = tokenizer.texts_to_sequences(data)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcfY8EIHv6tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, y = Reader(['rt-polarity.neg.txt', 'rt-polarity.pos.txt'])\n",
        "tensor, tokenizer = Indexing_padding(data, None)\n",
        "x_train, x_val, y_train, y_val = train_test_split(tensor, y, test_size=0.1, stratify=y, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx-hU4BNcLuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Buffer_size = len(x_train) + 1\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "Batch_size = 50\n",
        "epoch = 10\n",
        "learning_rate = 0.001\n",
        "dimension = 300\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(Buffer_size)\n",
        "train_dataset = train_dataset.batch(Batch_size, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(Buffer_size)\n",
        "test_dataset = test_dataset.batch(Batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44-nh2qe3JoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_46VNARZins",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class textCNN(Model):\n",
        "\n",
        "    def __init__(self, vocab_size, dimension=300):\n",
        "        super(textCNN, self).__init__()\n",
        "        self.embed = Embedding(vocab_size, dimension)\n",
        "        self.conv1 = Conv1D(100, 3, strides=1, padding='valid', kernel_regularizer=l2(3))\n",
        "        self.conv2 = Conv1D(100, 4, strides=1, padding='valid', kernel_regularizer=l2(3))\n",
        "        self.conv3 = Conv1D(100, 5, strides=1, padding='valid', kernel_regularizer=l2(3))\n",
        "        self.dropout = Dropout(0.5)\n",
        "        self.dense = Dense(2, activation='softmax', kernel_regularizer=l2(3))\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embed(x)\n",
        "        filter_result1 = ReLU()(GlobalMaxPooling1D()(self.conv1(x)))\n",
        "        filter_result2 = ReLU()(GlobalMaxPooling1D()(self.conv2(x)))\n",
        "        filter_result3 = ReLU()(GlobalMaxPooling1D()(self.conv3(x)))\n",
        "        x = tf.concat([filter_result1, filter_result2, filter_result3], axis=1)\n",
        "        x = self.dense(self.dropout(x))\n",
        "        return x\n",
        "\n",
        "model = textCNN(vocab_size, dimension)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0hb8NNy2Fez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, label):\n",
        "    with tf.GradientTape()as tape:\n",
        "        predictions = model(x)\n",
        "        loss = loss_object(label, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(label, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwQX4Efu7hUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def test_step(x, label):\n",
        "    predictions = model(x)\n",
        "    loss = loss_object(label, predictions)\n",
        "    test_loss(loss)\n",
        "    test_accuracy(label, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJfvAJ5bf_b3",
        "colab_type": "code",
        "outputId": "428a46a8-3345-474c-b724-9a3b437434da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for ep in range(epoch):\n",
        "    for x, label in train_dataset:\n",
        "        train_step(x,label)\n",
        "    for x, label in test_dataset:\n",
        "        test_step(x, label)\n",
        "    template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n",
        "    print (template.format(ep+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크: 1, 손실: 0.6205986142158508, 정확도: 66.15706634521484, 테스트 손실: 0.5748421549797058, 테스트 정확도: 71.61904907226562\n",
            "에포크: 2, 손실: 0.5290416479110718, 정확도: 77.07853698730469, 테스트 손실: 0.5633213520050049, 테스트 정확도: 73.0\n",
            "에포크: 3, 손실: 0.4716743528842926, 정확도: 83.37870788574219, 테스트 손실: 0.5577959418296814, 테스트 정확도: 73.74603271484375\n",
            "에포크: 4, 손실: 0.4372136890888214, 정확도: 87.06282806396484, 테스트 손실: 0.556642472743988, 테스트 정확도: 73.83333587646484\n",
            "에포크: 5, 손실: 0.41484883427619934, 정확도: 89.43036651611328, 테스트 손실: 0.5543820858001709, 테스트 정확도: 74.11428833007812\n",
            "에포크: 6, 손실: 0.39944005012512207, 정확도: 91.04886627197266, 테스트 손실: 0.55344158411026, 테스트 정확도: 74.38095092773438\n",
            "에포크: 7, 손실: 0.38819611072540283, 정확도: 92.22587585449219, 테스트 손실: 0.5528042912483215, 테스트 정확도: 74.51700592041016\n",
            "에포크: 8, 손실: 0.3796839714050293, 정확도: 93.11387634277344, 테스트 손실: 0.5522848963737488, 테스트 정확도: 74.66666412353516\n",
            "에포크: 9, 손실: 0.373024582862854, 정확도: 93.8068618774414, 테스트 손실: 0.5521225333213806, 테스트 정확도: 74.7513198852539\n",
            "에포크: 10, 손실: 0.36765700578689575, 정확도: 94.36753845214844, 테스트 손실: 0.55279141664505, 테스트 정확도: 74.70475769042969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf3JnlPBNfyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}